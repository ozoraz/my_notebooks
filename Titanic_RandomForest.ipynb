{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課題 タイタニック生存予測 ランダムフォレスト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ取得\n",
    "https://www.kaggle.com/c/titanic/data\n",
    "より,train.csvをダウンロードして、Jupyter Notebookと同じフォルダに保存しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv   train.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls ./input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ読み込み\n",
    "pandasを使用して、ダウンロードしたcsvファイルを読み込みましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data_train = pd.read_csv('./input/train.csv')\n",
    "data_test = pd.read_csv('./input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ確認\n",
    "データを読みこむことができたら、前処理や可視化を行っていくため、データの現状を確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Lennon, Mr. Denis</td>\n",
       "      <td>male</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name   Sex    Ticket    Cabin Embarked\n",
       "count                 891   891       891      204      889\n",
       "unique                891     2       681      147        3\n",
       "top     Lennon, Mr. Denis  male  CA. 2343  B96 B98        S\n",
       "freq                    1   577         7        4      644"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample\n",
    "pandas.DataFrame.sampleを使用して、何件か、データを取得し、データを眺めていきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johansson, Mr. Erik</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350052</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Backstrom, Mrs. Karl Alfred (Maria Mathilda Gu...</td>\n",
       "      <td>female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3101278</td>\n",
       "      <td>15.8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "395          396         0       3   \n",
       "85            86         1       3   \n",
       "201          202         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "395                                Johansson, Mr. Erik    male  22.0      0   \n",
       "85   Backstrom, Mrs. Karl Alfred (Maria Mathilda Gu...  female  33.0      3   \n",
       "201                                Sage, Mr. Frederick    male   NaN      8   \n",
       "\n",
       "     Parch    Ticket     Fare Cabin Embarked  \n",
       "395      0    350052   7.7958   NaN        S  \n",
       "85       0   3101278  15.8500   NaN        S  \n",
       "201      2  CA. 2343  69.5500   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.sample(n=3, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理について記述せよ\n",
    "以下の観点をすべて含めて記述しましょう。\n",
    "\n",
    "- 前処理とは何か\n",
    "- なぜ前処理を行う必要があるのか\n",
    "- 前処理は具体的に何を行うか(3つ以上記述せよ)\n",
    "- 前述した具体的な前処理について、その前処理を行うと何を得ることができるか(記述したそれぞれの前処理例について記述せよ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 答え：\n",
    "\n",
    "### 前処理とは何か\n",
    "　自分の扱いたいデータを理解し、データを扱いやすい形に整形すること\n",
    " \n",
    "### なぜ前処理を行う必要があるのか\n",
    "　一般的に、取得したそのままのデータは構造的にも論理的にも汚く乱雑であり、モデリングや分析のアルゴリズムを施せる状態になっていない。この問題を解消するために、前処理を行う必要がある\n",
    "\n",
    "### 前処理は具体的に何を行うか(3つ以上記述せよ)\n",
    "- 『データ基本変形』： マージ、ソート、グループ化・集計、行の抽出、列の選択\n",
    "- 『欠損値処理』： 欠損値を含む行・列の除去、平均値・中央値・最頻値で補完、重回帰やランダムフォレストなどの機械学習手法で補完\n",
    "- 『離散化』： クラスタリングや分位点分割などによる連続値の離散化\n",
    "- 『変数変換』： 対数変換、ロジスティック変換、主成分分析、変数同士の演算、クラスタリング、正規化などにより既存変数を変形し、新しい変数をつくる\n",
    "- 『ダミー化』： 多項目離散値をとる列を、複数列の真偽値に変換する\n",
    "- 『データの分割』： 学習用データとテスト用データを別のデータにする\n",
    " \n",
    "### 前述した具体的な前処理について、その前処理を行うと何を得ることができるか(記述したそれぞれの前処理例について記述せよ)\n",
    "- 『データ基本変形』： 不要な情報を除去できる、単一または少数のデータソースに変換できる、データを絞り込める\n",
    "- 『欠損値処理』： 欠損値があることで発生する分析の手間を減らせる、分析結果のブレやバイアスを減らせる\n",
    "- 『離散化』：　離散値を扱う分析モデルを適用できる、 連続値をグループで区分・整理できる\n",
    "- 『変数変換』： より分析にクリティカルな特徴量をつくり出せる、分析結果や予測の精度を向上できる\n",
    "- 『ダミー化』： ダミー化・行列化することで、多値離散値をうまく扱えない分析手法にも対応できる\n",
    "- 『データの分割』： モデルが過学習・未学習になっていないかどうかを検証できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2/前処理について記述せよ\n",
    "前処理について記述せよの調査により、データを確認する際にどのような点を見るとよいか、3つ以上記述せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 答え：\n",
    "- 問題解決につながる分析手法を予め複数検討しておき、それらを適用して成果を上げるためにはどのように前処理するべきか、という点\n",
    "- 入手できたデータセットが複数ある場合、少数に統合できないか。また、無駄な列や行を除去できないか、冗長な列や行を統合できないか、という点\n",
    "- 最大値、最小値、平均値、分散、などの統計情報から、欠損値、外れ値、異常値、偏った値などを検知できないか、という点\n",
    "- 表記揺れをはじめとする作り込まれた誤りが混入されていないか、という点\n",
    "- 繰り返されているパターンや、互いに強い相関関係を示す変数がないか、という点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 前処理を行う\n",
    "以下のコードを元に前処理を行いましょう。\n",
    "\n",
    "```前処理1```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Braund,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Cumings,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Heikkinen,</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Futrelle,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Allen,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex          Age  SibSp  Parch  \\\n",
       "0            1         0       3    male      Student      1      0   \n",
       "1            2         1       1  female        Adult      1      0   \n",
       "2            3         1       3  female  Young Adult      0      0   \n",
       "3            4         1       1  female  Young Adult      1      0   \n",
       "4            5         0       3    male  Young Adult      0      0   \n",
       "\n",
       "         Fare Cabin       Lname NamePrefix  \n",
       "0  1_quartile     N     Braund,        Mr.  \n",
       "1  4_quartile     C    Cumings,       Mrs.  \n",
       "2  1_quartile     N  Heikkinen,      Miss.  \n",
       "3  4_quartile     C   Futrelle,       Mrs.  \n",
       "4  2_quartile     N      Allen,        Mr.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simplify_ages(df):\n",
    "    df.Age = df.Age.fillna(-0.5)\n",
    "    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n",
    "    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "    categories = pd.cut(df.Age, bins, labels=group_names)\n",
    "    df.Age = categories\n",
    "    return df\n",
    "\n",
    "def simplify_cabins(df):\n",
    "    df.Cabin = df.Cabin.fillna('N')\n",
    "    df.Cabin = df.Cabin.apply(lambda x: x[0])\n",
    "    return df\n",
    "\n",
    "def simplify_fares(df):\n",
    "    df.Fare = df.Fare.fillna(-0.5)\n",
    "    bins = (-1, 0, 8, 15, 31, 1000)\n",
    "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n",
    "    categories = pd.cut(df.Fare, bins, labels=group_names)\n",
    "    df.Fare = categories\n",
    "    return df\n",
    "\n",
    "def format_name(df):\n",
    "    df['Lname'] = df.Name.apply(lambda x: x.split(' ')[0])\n",
    "    df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n",
    "    return df    \n",
    "\n",
    "def drop_features(df):\n",
    "    return df.drop(['Ticket', 'Name', 'Embarked'], axis=1)\n",
    "\n",
    "def transform_features(df):\n",
    "    df = simplify_ages(df)\n",
    "    df = simplify_cabins(df)\n",
    "    df = simplify_fares(df)\n",
    "    df = format_name(df)\n",
    "    df = drop_features(df)\n",
    "    return df\n",
    "\n",
    "data_train = transform_features(data_train)\n",
    "data_test = transform_features(data_test)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```前処理2```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>329</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>267</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Cabin  Lname  \\\n",
       "0            1         0       3    1    4      1      0     0      7    100   \n",
       "1            2         1       1    0    0      1      0     3      2    182   \n",
       "2            3         1       3    0    7      0      0     0      7    329   \n",
       "3            4         1       1    0    7      1      0     3      2    267   \n",
       "4            5         0       3    1    7      0      0     1      7     15   \n",
       "\n",
       "   NamePrefix  \n",
       "0          19  \n",
       "1          20  \n",
       "2          16  \n",
       "3          20  \n",
       "4          19  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "def encode_features(df_train, df_test):\n",
    "    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n",
    "    df_combined = pd.concat([df_train[features], df_test[features]])\n",
    "\n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df_combined[feature])\n",
    "        df_train[feature] = le.transform(df_train[feature])\n",
    "        df_test[feature] = le.transform(df_test[feature])\n",
    "    return df_train, df_test\n",
    "\n",
    "data_train, data_test = encode_features(data_train, data_test)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理の内容について記述せよ\n",
    "以下の観点をすべて含めて記述しましょう。\n",
    "```simplify_ages\n",
    "simplify_cabins\n",
    "simplify_fares\n",
    "format_name\n",
    "drop_features\n",
    "encode_features```\n",
    "- 以上のメソッドがそれぞれ何を行っているか記述せよ\n",
    "- それぞれなぜそのようなことを行っているか記述せよ(それによって得られるメリットまで考察すること)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 答え：\n",
    "### <前処理1について>  \n",
    "　学習データとテストデータの両方について、以下のように前処理を行なっている。\n",
    " \n",
    "- simplify_ages関数で、Age列の欠損値を'-0.5'で埋めてから、Age列の値を指定の区分でグループ分けし、それぞれのグループに該当する数値に['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']のカテゴリー値を割り当て、Age列の中身ごと入れ替えている。これにより、Age列の連続値を離散値に変換してデータの種類を減らし、後工程におけるデータ操作・データ分析の手間や処理量、過学習に陥る可能性を軽減できるメリットがある  \n",
    "\n",
    "\n",
    "- simplify_cabins関数で、Cabin列の欠損値を'N'で埋めてから、Cabin列の各文字列の先頭１文字と元の文字列を入れ替えている。これにより、複数文字だったデータ量を1文字まで削減し、また、データの種類を減らし、後工程におけるデータ操作・データ分析の手間や処理量、過学習に陥る可能性を軽減できるメリットがある  \n",
    "\n",
    "\n",
    "- simplify_fares関数で、Fare列の欠損値を'-0.5'で埋めてから、Fare列の値を指定の区分でグループ分けし、それぞれのグループに該当する数値に['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']のカテゴリー値を割り当て、Fare列の中身ごと入れ替えている。これにより、Fare列の連続値を離散値に変換してデータの種類を減らし、後工程におけるデータ操作・データ分析の手間や処理量、過学習に陥る可能性を軽減できるメリットがある  \n",
    "\n",
    "\n",
    "- format_name関数で、Name列の各文字列をスペースで分割してリストに格納。リストの1番目の要素と2番目の要素を、それぞれ'Lname'、'NamePrefix'という新しい列にまとめて、データセットに加えている。これにより、元のName列の各名前の文字列から、'苗字'と'称号'の文字列を機械的に取り出すことができる。Name列から、これら２つだけを取り出したので、データ量とデータの種類を減らして後工程におけるデータ操作・データ分析の手間や処理量、過学習に陥る可能性を軽減できるメリットがある。それに加えて、'苗字'を元に家族をグルーピングしたり、'称号'を用いて社会的地位をグルーピングしたりといった、後の分析に使える新しい特徴量を取り出せるというメリットがある  \n",
    "\n",
    "\n",
    "- drop_features関数で、データセットから['Ticket', 'Name', 'Embarked']の３つの列を削除している。これにより、分析に不要と判断した情報を削除して、後工程におけるデータ操作・データ分析の手間や処理量を軽減できるメリットがある。それに加えて、これらの値が分析結果にノイズをもたらす可能性を排除できるというメリットがある  \n",
    "\n",
    "\n",
    "### <前処理2について>  \n",
    "　学習データとテストデータの両方について、以下のように前処理を行なっている。\n",
    "- encode_features関数で、データセットの['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']の６つの列について、文字列や文字で示されていたカテゴリー値を、数値(ラベル)で置き換えている。これにより、データセットについて、文字や文字列を扱えない分析手法でも適用できるようになるというメリットがある。また、文字列から数値への変換によるデータ量の削減により、後工程におけるデータ操作・データ分析の手間や処理量、過学習に陥る可能性を軽減できるメリットがある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## モデル選択について記述せよ\n",
    "今回使用するモデルは決定していますが、モデル選択をする際の演習を行いましょう。\n",
    "\n",
    "- 今回は、生存予測（分類）を行いますが、この分類について使用できそうな手法を4つ以上しらべて記述せよ。\n",
    "- その手法の概要をそれぞれ記述せよ\n",
    "- その手法の長所/短所をそれぞれ3つずつ、記述したすべての手法において記述せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 答え：\n",
    "### ①k近傍法\n",
    "#### 概要\n",
    "　分類対象について、その近くにある（近傍の）分類済み対象群の個数を元に分類する。すなわち、k 個の最近傍の分類済み対象群で最も多い分類を、対象の分類に割り当てる。対象は、特徴空間におけるベクトルで示される。分類済み対象群とは、分類ラベルがつけられた特徴空間におけるベクトル群である。近さを測る距離は一般にユークリッド距離が用いられる\n",
    "#### 長所\n",
    "- 距離と近傍のラベルのみにより分類できるため、直感的に理解しやすい\n",
    "- 連続値をとる変数についても適用可能である\n",
    "- データ量が無限に近づくほど、分類精度が高くなる\n",
    "\n",
    "#### 短所\n",
    "- 原理的に、個体数が最も多い分類が採用されやすい\n",
    "- ノイズや不適切な特徴量の影響を受けやすい\n",
    "- 高次元空間は広大になるという所謂「次元の呪い」故に、次数が大きい場合には膨大な数の分類済み対象が必要になる\n",
    "\n",
    "### ②XGBoost\n",
    "#### 概要\n",
    "　XGBoostとは，Gradient BoostingとRandom Forestsを組み合わせたアンサンブル学習である。\n",
    "Boosted treesの予測精度はRandom Forestsよりも向上するが、チューニングが必要なパラメータが複数存在する。一方、Random Forestsはチューニングが不要だが、学習データに依存しやすく、過学習となりやすい\n",
    "\n",
    "#### 長所\n",
    "- 高いスケーリング性を持つend-to-endなtree boostingシステムをもつ\n",
    "- 値が欠損、0が多い、one-hot encodingなどの特殊な処理を施したデータなどについて，予め分岐の方向を決めるアルゴリズムを導入している\n",
    "- CPU外(out-of-core)での学習が可能であり、計算速度が高速化されている\n",
    "\n",
    "#### 短所\n",
    "- 複数のパラメータ調整によるチューニングが必要であり、最適化はグリッドサーチやCross Validationを複数行う\n",
    "- 汎化能力を上げるために、学習率(XGBoostパッケージではパラメータeta)を下げていき、その都度最適化を行う\n",
    "- 線形分離可能パターンに対してはうまく機能しない可能性が高い\n",
    "\n",
    "### ③パーセプトロン\n",
    "#### 概要\n",
    "　入力、中間、出力の3層からなるニューラルネットワークの手法。バックプロパゲーションを用いた学習が一般的。複雑な表現を再現できるが、その分過学習もしやすい。ディープラーニングが登場する前の代表的なニューラルネットワークの手法\n",
    "\n",
    "#### 長所\n",
    "- シンプルなネットワークでありながら学習能力を持つ\n",
    "- 多層パーセプトロンは、誤差逆伝播学習法で学習させることで、線型分離不可能な問題が解けるように、単純パーセプトロンの限界を克服した\n",
    "- 多層パーセプトロンは適応度近似のような極めて複雑な問題に対する近似解をしばしば与える\n",
    "\n",
    "#### 短所\n",
    "- 単純パーセプトロンでは、線形分離可能なものしか学習できない\n",
    "- 階層型ネットワークのパーセプトロンでは、階層が少ないと解けない問題もある\n",
    "- 複雑なネットワークはうまく学習するのがとても難しい。理論的に優れた性能が発揮できるということはわかっていても、そもそも学習ができない\n",
    "\n",
    "### ④サポートベクターマシーン(SVM)\n",
    "#### 概要\n",
    "　線形入力素子を利用して 2 クラスのパターン識別器を構成する手法である。訓練サンプルから、各データ点との距離が最大となるマージン最大化超平面を求めるという基準（超平面分離定理）で線形入力素子のパラメータを学習する\n",
    "\n",
    "#### 長所\n",
    "- 非線形分類問題にも優れた性能を発揮することがわかり、近年特に注目を集めている\n",
    "- 「マージン最大化」というアイデア等で汎化能力も高め、現在知られている方法としては、最も優秀なパターン識別能力を持つとされている\n",
    "- 局所解収束の問題が無い\n",
    "\n",
    "#### 短所\n",
    "- データを2つのグループに分類する問題には優れているが、多クラスの分類にそのまま適用出来ない\n",
    "- カーネル関数の選択の基準も無い等の課題も指摘されている\n",
    "- 計算量が多い\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## モデル選択の基準\n",
    "下記の参考資料を元に、どのような視点からモデルを選択すれば良いか、最低でも3つ以上の視点を記述すること(他の参考資料でも構わない、その場合参考資料を明記すること)\n",
    "- https://docs.microsoft.com/ja-jp/azure/machine-learning/machine-learning-algorithm-choice\n",
    "- https://datumstudio.jp/blog/機械学習におけるモデルの選択方法について"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 答え：\n",
    "- 精度について、可能な限り最も正確な回答を得ることが常に必要であるとは限らない。 使用目的によっては、近似で十分な場合がある。 その場合は、より大まかな方法を使用することで、処理時間を大幅に削減できることがある。 近似手法のもう 1 つの利点は、一般に 過学習が回避される傾向があることである\n",
    "\n",
    "\n",
    "- トレーニング時間について、モデルのトレーニングに必要な分数または時間数は、アルゴリズムによって大きく異なる。 通常、トレーニング時間は精度と密接に関係する。さらに、一部のアルゴリズムは他よりデータ ポイントの数に大きく影響を受ける。 時間が限られている場合、アルゴリズムの選択を左右することがある。データセットが大きい場合は特にそうである\n",
    "\n",
    "\n",
    "- 線形アルゴリズムは最初に使用する方法として非常に一般的である。 アルゴリズムが簡単で、速くトレーニングできる傾向がある\n",
    "\n",
    "\n",
    "- パラメーターの数について、パラメーターは、アルゴリズムを設定するときに使用する。 エラーの許容範囲や反復回数などのアルゴリズムの動作に影響を与える値、またはアルゴリズムの動作のバリエーションのオプションである。 アルゴリズムのトレーニング時間と精度は、設定の適切さに大きな影響を受けることがある。 通常、パラメーター数の多いアルゴリズムは、適切な組み合わせを見つけるのに多くの試行錯誤が必要である\n",
    "\n",
    "\n",
    "- 分類や回帰問題の手法に着目するとき、モデル選択の評価として重要なのは「予測精度」と「中身のわかりやすさ」の2点である。「予測精度」は学習から得られたモデル(近似関数)が判別や回帰の値をどれだけ正確に出力するかという指標で、学習データのみ精度が高くその他で精度が低い過学習の問題を解消できるならば非線形性を有する手法ほど精度が高い傾向にある。一方「中身のわかりやすさ」は、モデルをひとつの入出力器とみなした場合、入力に相当する説明変数と出力に相当する目的変数(予測値)間の関係が陽に解釈できるかどうかに依存する。入出力の関係性がパラメータなどを通して理解し易いならば、モデルはホワイトボックスとして因果類推に役立つ。このように、分類や回帰問題に対する機械学習の手法は「予測精度」と「中身のわかりやすさ」の基準において各々が長所と短所を有す。したがって分析の目的に応じて手法の特徴を鑑みモデルを選択することが肝要である\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル選択におけるデータ可視化\n",
    "モデルを選択する際にデータ可視化を行い、データの特徴を把握した上で、モデルを選択することができます。今回は、その例を体験してみましょう  \n",
    "```import```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```barplot```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11895a208>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEFCAYAAADqujDUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqQCIiKTU/wNrrm4W6FN9ZAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1188fb588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=\"Age\", y=\"Survived\", hue=\"Sex\", data=data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```pointplot```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEFCAYAAADqujDUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUgIQESlRSgAiIiVKCUBEpET9f06R8W8/5aMXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bdf3908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pointplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=data_train,\n",
    "              palette={1: \"blue\", 0: \"pink\"},\n",
    "              markers=[\"*\", \"o\"], linestyles=[\"-\", \"--\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ可視化の結果について考察せよ\n",
    "以下の観点をすべて含めて記述しましょう。\n",
    "- 上記の２つの可視化から分かったことについて考察せよ。\n",
    "- 上記の考察結果から、モデル選択を考える場合、どのようなことが考えられるか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 答え：\n",
    "\n",
    "### 上記の２つの可視化から分かったことについて考察せよ。\n",
    "　『barplot』より、'Child'の年齢区分を例外としても、全体的に女性の生存率が男性よりも高い。そして'Baby'は男女生存率がどちらも高い。'Child'は男女生存率の高低が全体と逆転している。これらのことから、ほとんどの年齢で女性が優先的に避難・救助されたということ、幼子と子供は男女関係なく優先的に避難・救助されたということが考えられる　　\n",
    "\n",
    "　『pointplot』より、どの'Pclass'であっても、女性の生存率が男性よりも高い。また、男女ともに'Pclass'が高いものほど生存率が高い。これらのことから、男女とも'Pclass'の高いものから優先的に避難・救助されたということが考えられる　　\n",
    "\n",
    "　上記のことから、男女を示す変数'Sex'、年齢区分を示す変数'Age'、乗客の階級を示す変数'Pclass'の３つの変数が、生存予測にあたって影響度が大きい変数と考えられる\n",
    " \n",
    "### 上記の考察結果から、モデル選択を考える場合、どのようなことが考えられるか\n",
    "　生存予測にあたって影響度が大きいと考えられる３つの変数は、実質的に名義尺度であり、演算に意味を持たない離散値である。このことから、分類のモデルであっても連続値を入力とするロジスティック回帰などのモデルは馴染まないと考えられる。また、これら３つの変数が取りうる値はそれぞれ２値、６値、３値とパターンが少ないので、複雑で自由度の高いモデルを選択する必要はないと考えられる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの分割\n",
    "それでは、テストデータの作成を行いましょう。学習データとテストデータの比は8:2とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data_train.drop(['Survived', 'PassengerId'], axis=1)\n",
    "y = data_train['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ランダムフォレストについて記述せよ\n",
    "今回は、ランダムフォレストという手法を使用します。\n",
    "\n",
    "以下の観点をすべて含めて記述しましょう。\n",
    "\n",
    "- 決定木とはどのような手法か\n",
    "- ランダムフォレストとはどのような手法か\n",
    "- ランダムフォレストの長所と短所をそれぞれ3つ以上挙げてください。\n",
    "- 今回の目的からランダムフォレストの手法が適する理由を考察し、記述せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 答え：\n",
    "### 決定木とはどのような手法か\n",
    "　決定木とは予測モデルであり、ある事項に対する観察結果から、その事項の目標値に関する結論を導く。内部節点は変数に対応し、子節点への枝はその変数の取り得る値を示す。アルゴリズムは、目的変数と説明変数のデータから木構造の分類器を生成し、トップダウンに、再帰的にデータを分割していく。実数値をとる関数の近似に用いる場合には回帰木、分類に用いる場合には分類木と呼ばれる\n",
    " \n",
    "### ランダムフォレストとはどのような手法か\n",
    "　ランダムフォレストは、決定木を複数組み合わせて、各決定木の予測結果を多数決することによって結果を得る、分類、回帰、クラスタリングに用いられるアンサンブル学習である。それぞれの決定木で使う特徴量をランダムに選択することで各決定木の予測結果をバラつかせ、過学習に陥り易いという決定木の弱点を補っている\n",
    "\n",
    "### ランダムフォレストの長所と短所をそれぞれ3つ以上挙げてください。\n",
    "#### 長所\n",
    "- 正規化・標準化を考える必要が無く、連続値・離散値が混在していても使える\n",
    "- 決定木の予測精度を維持したままで、過学習を起こしにくい\n",
    "- 特徴量の重要度を学習とともに計算できる\n",
    "\n",
    "#### 短所\n",
    "- 原理的に、内部の決定木が種類・深さともに多様になるため「中身の分かりやすさ」が確保しにくい\n",
    "- テキストデータなど、高次元で疎なデータに対してはうまく機能しない傾向にある\n",
    "- 線形モデルに比べて、メモリ消費が多い\n",
    "\n",
    "### 今回の目的からランダムフォレストの手法が適する理由を考察し、記述せよ\n",
    "　今回の目的は、タイタニックの乗客データから事故における生存予測を行う分類問題である。学習データが８９１件と少なく、年齢や料金などの連続値や、名前や客室名などの多値離散値が含まれていることから、採用した分類モデルが過学習になりやすいデータであるといえる。ランダムフォレストは、連続値・離散値をともに扱えることに加えて、決定木の予測精度を維持したまま過学習を起こしにくいという長所があるため、この懸案に対処できることになる。また、特徴量の重要度を計算できることから、このような事故において生死を分ける要因を突き止めて、再発防止のための教訓を得ることもできるだろう。こうした理由により、ランダムフォレストの手法はタイタニック生存予測に適していると考える"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "ランダムフォレストを使用して、学習を行いましょう。  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracyを求めよ\n",
    "学習が終わったら、accuracyを求めましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.977528089888\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 精度を高める\n",
    "この課題では75%以上の精度が出ていた場合、合格とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776536312849\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメータについて\n",
    "- ハイパーパラメーターとは何か\n",
    "- ランダムフォレストにおいてどのようなハイパーパラメーターがあるか4つ以上記述せよ\n",
    "- 記述したハイパーパラメーターにおいて、それぞれどのような値が存在するか記述せよ（そのハイパーパラメーターを変化させるとどのようなことが起きるかも記述すること）  \n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ハイパーパラメーターとは何か\n",
    " モデルが学習を行う際に、人間が予め設定しておかなければいけないパラメータのこと。機械学習が自動で決められる範囲の外のパラメータのため、\"ハイパー\"が冠される。調整については、先例や経験に基づいて試行錯誤していく手動調整方法と、ランダムにパラメータを試していくランダムサーチやパラメータ候補を総当たりで調べるグリッドサーチなどの自動調整方法がある\n",
    "\n",
    "### ランダムフォレストにおいてどのようなハイパーパラメーターがあるか4つ以上記述せよ\n",
    "- 『n_estimators』：多数決判断に用いる決定木をいくつ作るか\n",
    "- 『max_features』：特徴量をいくつまで用いるかの最大数\n",
    "- 『max_depth』：多数決判断に用いる決定木の深さの最大数\n",
    "- 『min_samples_split』：多数決判断に用いる決定木の葉ノード内で分割されるサンプルの最小数\n",
    "\n",
    "### 記述したハイパーパラメーターにおいて、それぞれどのような値が存在するか記述せよ\n",
    "- 『n_estimators』：整数値（その数がそのまま採用される）。デフォルト値は１０\n",
    "- 『max_features』：整数値（その数がそのまま採用される）、小数（それと特徴量数を乗算した数が採用される）、“auto”・“sqrt”（特徴量数の平方根が採用される）、“log2”（２を底とする特徴量数の対数が採用される）、None（特徴量数がそのまま採用される）。デフォルト値は“auto”\n",
    "- 『max_depth』：整数値（その数がそのまま採用される）、None（葉ノードの全ての要素が完全に分類されるか、min_samples_splitで指定された数まで分類されるまで深くなる）、デフォルト値はNone\n",
    "- 『min_samples_split』：整数値（その数がそのまま採用される）、小数（それとサンプル数を乗算した数が採用される）。デフォルト値は２"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## チューニング\n",
    "思うような精度が出ていない場合、チューニングを行う必要があります。\n",
    "今回はハイパーパラメーターを変更し、チューニングを行いましょう。\n",
    "以下の観点からチューニングを複数行い、精度の向上を目指します。\n",
    "\n",
    "- 'n_estimators': [4, 6, 9],\n",
    "- 'max_features': ['log2', 'sqrt','auto'],\n",
    "- 'criterion': ['entropy', 'gini'],\n",
    "- 'max_depth': [2, 3, 5, 10],\n",
    "- 'min_samples_split': [2, 3, 5],\n",
    "- 'min_samples_leaf': [1,5,8]  \n",
    "\n",
    "上記は、それぞれのハイパーパラメーターの例を示しています。’n_estimators’であれば、4,6,9を試してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.854749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.844101</td>\n",
       "      <td>0.854749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.844101</td>\n",
       "      <td>0.854749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.817416</td>\n",
       "      <td>0.854749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.854749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2  3  4  5         6         7\n",
       "123  4  sqrt  gini  3  5  1  0.837079  0.854749\n",
       "47   4  log2  gini  3  2  8  0.844101  0.854749\n",
       "53   4  log2  gini  3  5  8  0.844101  0.854749\n",
       "52   4  log2  gini  3  5  5  0.817416  0.854749\n",
       "51   4  log2  gini  3  5  1  0.837079  0.854749"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = []\n",
    "for h in [4, 6, 9]:\n",
    "    for i in ['log2', 'sqrt','auto']:\n",
    "        for j in ['entropy', 'gini']:\n",
    "            for k in [2, 3, 5, 10]:\n",
    "                for l in  [2, 3, 5]:\n",
    "                    for m in [1,5,8]:\n",
    "                        clf = RandomForestClassifier(random_state=0, \n",
    "                                                     n_estimators=h, max_features=i, criterion=j, \n",
    "                                                     max_depth=k, min_samples_split=l, min_samples_leaf=m)\n",
    "                        clf.fit(X_train, y_train)\n",
    "                        list.append([h, i, j, k, l, m, clf.score(X_train, y_train), \\\n",
    "                                     clf.score(X_test, y_test)])\n",
    "\n",
    "pd.DataFrame(list).sort_values(by=7, ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検証について記述せよ\n",
    "機械学習で思うようなAccuracyを求めることができたら、検証を行いましょう。\n",
    "以下の観点をすべて含めて記述しましょう。\n",
    "- 検証は何か\n",
    "- なぜ検証を行う必要があるのか(Accuracyだけではダメな理由も含めること)\n",
    "- 主な検証方法について2つ以上記述せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 答え：\n",
    "### 検証は何か\n",
    "　モデルが過学習または未学習に陥っていないか、モデルの予測値と実際値の乖離具合がどうなっているか、確認し対策するための工程である\n",
    "\n",
    "### なぜ検証を行う必要があるのか(Accuracyだけではダメな理由も含めること)\n",
    "　分類問題では、必ず２つ以上の分類先がある。つまり、２種類以上の予測値を立てて実際値と比較するのである。Accuracyは(予測が○)で(実際も○)と、(予測が✖️)で(実際も✖️)の２パターンを問題にした評価方法であり、過学習と未学習の検知からモデルの汎化能力を測ることはできる。  \n",
    "　しかし、ここでは、(予測が○)で(実際が✖️)と、(予測が✖️)で(実際が○)という２パターンも捉えなければ、予測値vs実際値の二軸での評価として不十分である。具体的には、後述の２パターンも問題として前述の２パターンと混合し、予測値と実際値の乖離具合がどうなっているかを確認する必要がある。  \n",
    "　上述したように、予測値vs実際値の二軸で、４パターン以上の予測値と実際値の乖離具合を確認した上で、各種パラメータを調整したり適用モデルを変えてみるなどの判断を行い、汎化能力と予測精度をより一層向上させる工夫ができるような検証にしなければならない。  \n",
    "　以上により検証を行うことは必要で、Accuracyだけでは不十分である\n",
    "\n",
    "### 主な検証方法について2つ以上記述せよ\n",
    "- 『ホールドアウト法』は、元のデータセットを学習データとテスタデータに分割し、学習データセットはモデルの学習に使用され、テストデータセットはモデルの性能を評価するために使われる。学習データセットとテストデータの分け方によって性能評価が左右されやすい\n",
    "\n",
    "\n",
    "- 『k分割交差検証』は、データをK個に分割する。そして、そのうちの1つをテストデータとし、残る K−1 個のデータを学習データとする。この際、K個のデータ分割はランダムになる。そして、データ分割が完了したら、実際にK-1のデータセットで学習を行い、1つに分割されたテストデータでテストを行う。この学習、テストの作業を分割されたK個のそれぞれのデータの組み合わせに対してK回繰り返す。最後にそれぞれの回で導き出した精度の平均値をもって性能評価とする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFoldについて記述せよ\n",
    "今回はKFold(K-分割交差検証)を使用して、検証を行います。\n",
    "以下の観点をすべて含めて記述しましょう。\n",
    "\n",
    "- K-分割交差検証について説明せよ\n",
    "- K-分割交差検証はデータセットを何個に分割するか\n",
    "- データセットを分割する際、その個数はどのように考えると良いか\n",
    "- K-分割交差検証は何回の検証を行うか\n",
    "- K-分割交差検証の結果は、最終的にどのように求められるか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-分割交差検証について説明せよ\n",
    "　手許のデータのうち、いくらかを学習データ、残りをテストデータにして性能評価を行う検証方法\n",
    "\n",
    "### K-分割交差検証はデータセットを何個に分割するか\n",
    "データをk個に分割する\n",
    "\n",
    "### データセットを分割する際、その個数はどのように考えると良いか\n",
    "十分な数のデータがある場合には、k=5, 10程度にすることが一般的であり、データが少ない場合には、k=全件として性能評価の品質確保を図る\n",
    "\n",
    "### K-分割交差検証は何回の検証を行うか\n",
    "そのk通りの訓練およびテストを行う\n",
    "\n",
    "### K-分割交差検証の結果は、最終的にどのように求められるか\n",
    "各回の性能評価結果の平均値をもって、最終的な性能評価とする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFoldを実施する\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "sklearn.model_selection.KFoldを使用して、KFoldを実施しましょう\n",
    "## Kfoldの結果を確認する\n",
    "Kfoldの結果(Mean Accuracy)が75%以上になっていれば成功です。\n",
    "そうでなければ、再度モデルのチューニングを行いましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.779937578027\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 改めてデータセットをつくる\n",
    "X = data_train.drop(['Survived', 'PassengerId'], axis=1)\n",
    "y = data_train['Survived']\n",
    "\n",
    "# 配列化する\n",
    "mX = X.as_matrix()\n",
    "my = y.as_matrix()\n",
    "\n",
    "# 先述の「チューニング」でaccuracyが高かったハイパーパラメータで、\n",
    "# ランダムフォレストのインスタンスをつくる\n",
    "clf = RandomForestClassifier(random_state=0, \n",
    "                             n_estimators=4, \n",
    "                             max_features='log2', \n",
    "                             criterion='gini', \n",
    "                             max_depth=3, \n",
    "                             min_samples_split=5, \n",
    "                             min_samples_leaf=8)\n",
    "\n",
    "# k = 10 でKfold\n",
    "kf = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "\n",
    "# Kfoldで分割したインデクスでデータを切りわけ、\n",
    "# 学習データで学習、テストデータでAccuracy算出、リストに格納\n",
    "acc_list = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    clf.fit(mX[train_index], my[train_index])\n",
    "    acc_list.append(clf.score(mX[test_index], my[test_index]))\n",
    "\n",
    "# Accuracyの平均を出力\n",
    "print(sum(acc_list)/len(acc_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## どの特徴量が重要であったかを調査する\n",
    "sklearnでランダムフォレストを実装すると用意にどのどの特徴量が重要であったかを判明させることができます。\n",
    "feature_importances_メソッドを使用して、判明させましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>important</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.389816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>0.238995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NamePrefix</th>\n",
       "      <td>0.146130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>0.115397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.044348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lname</th>\n",
       "      <td>0.026112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.023481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.015721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            important\n",
       "Sex          0.389816\n",
       "Cabin        0.238995\n",
       "NamePrefix   0.146130\n",
       "Pclass       0.115397\n",
       "SibSp        0.044348\n",
       "Lname        0.026112\n",
       "Age          0.023481\n",
       "Parch        0.015721\n",
       "Fare         0.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.feature_importances_, index=X.columns, columns=['important']).\\\n",
    "sort_values(by='important', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
